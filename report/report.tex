

%=======================   Default Templete   ==================
\documentclass[11pt]{article}
\usepackage{graphicx}

% file with some default definations
\input{structure.tex}
\usepackage{listings}
\lstset{language=Python, basicstyle=\normalsize\sffamily\linespread{0.8}, numbers=left, numberstyle=\small, stepnumber=1, numbersep=5pt}
\usepackage{fancyhdr}
\usepackage{pdfpages} 
\setlength{\parindent}{0pt}
\fancypagestyle{note_1}{\fancyfoot[R]{\textit{* These kind of auction are sealed bid auction.}}}
\pagestyle{fancy}
\fancyhf{}
\lhead{\textbf{\NAME\ (\ANDREWID)}}
\chead{\textbf{UGP Report}}
\rhead{\COURSE}
\usepackage{cite}

%==================Header details======================
\newcommand\NAME{Raghukul Raman}
\newcommand\ANDREWID{160538}
\newcommand\HWNUM{4}
\newcommand\COURSE{CS395}
%======================================================

% available formatted sections:
% - COMMAND LINE ENVIRONMENT: \begin{commandline} \end{commandline}
% - FILE CONTENTS ENVIRONMENT: \begin{file}[optional filename, defaults to "File"]
% - NUMBERED QUESTIONS ENVIRONMENT: \begin{question}[optional title]
% - WARNING TEXT ENVIRONMENT(can also be used for note): \begin{warn}[optional title, defaults to "Warning:"]
% - INFORMATION ENVIRONMENT(can be used to mention given details): \begin{info}[optional title, defaults to "Info:"]

%===============================================================
\begin{document}
\includepdf[page={1}]{first_page.pdf}
\section*{Abstract}
In the modern day computing where application response is a 
critical metric, in memory databases are gaining popularity. In-memory 
databases primarily use main memory for data storage. These databases 
are becoming a crucial part of many applications due to the availability 
of less expensive RAM, and the demand for high response time.  Some of 
the cases where in-memory databases perform exceptionally well are 
Queues, sticky sessions, caching, real-time data analysis, etc.
\\

Generally, these in-memory databases are implemented as key-value 
stores; some well know key-value stores are Redis, Memcached, Hazelcast, 
etc. Large scale caching can be done by scaling the instances of these 
databases. Dynamic scaling of instances can provide cost-effective 
key-value storage services.This project aims at analyzing and providing 
an auto-scaling solution to this problem.
\\

We try to collect statistics for different queries on different node 
configurations and try to find possible bottlenecks in the cluster based 
system. We analyze by scaling redis horizontally as well as vertically. 
For analyzing clusters we use an open source tool called Twemproxy (a 
fast, light-weight proxy for Memcached and redis). We limit resources 
and measure performance for these configurations. We also try to build a 
system which can be used to interact with the cluster and efficiently 
shard the requests among different instances.




% In the modern world where application response is a critical metric,
% in memory databases are gaining wide popularity. In-memory databases primarily relies
% on main memory for data storage. These databases are becoming a crucial part of many
% applications due to the availability of less expensive RAM, and the demand for high response time.
% Accessing data in memory eliminates seek time when querying the data,
% which provides faster and more predictable performance than disk.
% Some of the cases where in-memory databases perform exceptionally well are Queues,
% sticky sessions, caching, real-time analysis of data, etc. \\
% 
% Generally, these in-memory databases are implemented as key-value stores;
% some traditional ones are Redis, Memcached, Hazelcast, etc. Large scale caching
% can be done by scaling the instances of these databases. One way is running a fixed number of instances,
% while the other is to scale up/down based on the load that our sever gets.
% This project aims at analyzing and providing an auto-scaling solution to this problem. \\
% 
% First, we try to collect statistics for different queries on different node
% configurations and try to find possible bottlenecks in the cluster based system.
% We analyze by scaling redis horizontally as well as vertically and try to explain the results.
% For analyzing clusters we use an open source tool called Twemproxy
% (a fast, light-weight proxy for Memcached and redis). We try to limit resources and
% measure performance for these configurations. We also try to build a system which can
% be used to interact with the cluster and efficiently shard the requests among
% different instances. Second part of the project is to give a scaling algorithm based on machine learning
% and some statistical predictions.




\pagebreak
\section*{Introduction}
\subsection*{Key Value Stores}
Key value stores are a special kind of database management system, where the 
data is organized in just $2$ columns - a key, and a value. Here the key is mostly
text, while the value can be anything and is simply an object. The actual data
essentially becomes "value", which is indexed with "key", so whole data 
becomes schema-less and is just organized in just $2$ columns. One important property
is that since the data is indexed by just the keys, there is a lot of scope of
distributing keys over different instances, making the system highly scalable.
\\

These kind of databases fall into the category of nosql data stores, satisfying the 
BASE properties (Basically Available, Soft state, Eventually consistent).
In the contezt of the CAP theorem (Consistency, Availability, Partition tolerance), these
databases fall into the category of CP. Since these databases are generally implemented
in cluster mode, we cannot gurantee availability on data.
\\

These databases are generally in-memory which reside in main memory. In-memory
databases are faster than disk-optimized databases because disk access is 
slower than memory access, the internal optimization algorithms 
are simpler and execute fewer CPU instructions.

\subsection*{Scalability}
\textbf{Scalability} is the property of a system to handle a growing amount of work
by adding resources to the system [\textit{Bondi, Andre - Characteristics of
scalability and their impact on performance, 2000}]. In layman terms, when
you realise your system is getting slow and is unable to handle
the current number of requests, you need to scale the system. Scaling 
can be done in two ways:

\begin{itemize}
    \item \textbf{Vertical Scaling:} Increasing the resources in the server
            which we are currently using, i.e increase the amount of CPU, GPU,
            CPU, etc. Vertical scaling generally costly, also it may
            require the system to go down for a moment when the scaling takes
            place (need for downtime).
    \item \textbf{Horizontal Scaling:} Increasing the number of servers (instances).
            This would lead to decrease in the overall load on the system, if requests
            are sharded properly. This kind of scaling solution is typically popular 
            in tech industries, as it makes the system fault tolerant (single point of
            failure reduced). Important advantage of this method is that it can provide
            administrators with the ability to increase capacity on the fly.
\end{itemize}

\subsection*{Redis}
Redis is an open source (BSD licensed), in-memory data structure store,
used as a database, cache and message broker [\textit{redis.io}] \cite{latexcompanion}


\pagebreak
\section*{Design Details}



\pagebreak
\begin{thebibliography}{9}

\bibitem{redis}
Redis documentation,
\texttt{redis.io}
        
\bibitem{latexcompanion} 
Michel Goossens, Frank Mittelbach, and Alexander Samarin. 
\textit{The \LaTeX\ Companion}. 
Addison-Wesley, Reading, Massachusetts, 1993.
%  
% \bibitem{einstein} 
% Albert Einstein. 
% \textit{Zur Elektrodynamik bewegter K{\"o}rper}. (German) 
% [\textit{On the electrodynamics of moving bodies}]. 
% Annalen der Physik, 322(10):891â€“921, 1905.
%  
% \bibitem{knuthwebsite} 
% Knuth: Computers and Typesetting,
% \\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}
\end{thebibliography}

\end{document}
